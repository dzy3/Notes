# BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition

## Abstract

我们的工作重点是解决具有挑战性但自然的视觉识别任务的长尾数据分布(即少数类占用了大部分数据，而大多数类很少有样本)。在文献中，为了缓解长尾问题的极端不平衡，提出了类的再平衡策略(如重新加权和重新采样)是突出而有效的方法。在本文中，我们首先发现这些再平衡方法能够取得较好的识别精度是因为它们能够显著地促进深度网络的分类器学习。但与此同时，它们也会在一定程度上意外地损害已学习的深层特征的代表性能力。因此，我们提出了一种统一的双侧分支网络(BBN)，可以同时兼顾表示学习和分类器学习，每个分支都独立完成自己的任务。特别是我们的BBN模型进一步配备了一种新的累积学习策略，即先学习通用模式，然后逐渐关注尾部数据。在四个基准数据集上的广泛实验，包括大规模的自然数据集，证明了所提出的BBN可以显著优于最先进的方法。此外，验证实验可以证明我们的初步发现和在长尾BBN中定制设计的有效性。我们的方法在2019年的iNaturalist大规模物种分类竞赛中获得了第一名，我们的代码是开源的，网址是https://github.com/Megvii-Nanjing/BBN。

![image-20201109095419990](F:\Paper笔记\Notes\image-20201109095419990.png)

图片1 真实的大型数据集往往表现出长尾分布的现象。这种极端的不平衡给分类精度带来了巨大的挑战，特别是对尾部类。类重新平衡策略可以产生更精确的分类，以解决长尾问题。在本文中，我们揭示了这些策略的机制是显著促进分类器的学习，但会在一定程度上意外地损害已学习的深层特征的代表性能力。从概念上讲，在重新平衡后，决策边界(即黑色实弧)倾向于对尾部数据(即红色方块)进行准确分类。然而，每个类的类内分布变得更加可分离。定量结果如图2所示，更多的分析可以在补充资料中找到。

## Introduction

![image-20201109100850189](F:\Paper笔记\Notes\image-20201109100850189.png)

图片2 在两个长尾数据集CIFAR-100IR50和CIFAR-10-IR50[3]上不同表示学习和分类器学习方式的Top-1错误率。“CE”(交叉熵)、“RW”(重加权)和“RS”(重抽样)是进行学习的方式。可以看到，在固定表示(比较三个块在垂直方向的错误率)时，RW/RS训练的分类器错误率比CE低。而在固定分类器时(水平方向比较错误率)，CE训练的表示法比RW/RS训练的表示法错误率低得惊人。实验细节见第3节。

​	随着深度卷积神经网络(CNNs)研究的出现，图像分类的性能得到了令人难以置信的发展。成功无疑离不开可用的高质量的大规模数据集，如ImageNet ILSVRC 2012 [24]， MS COCO [18]， place Database[39]等。与这些呈现出类标签大致均匀分布的视觉识别数据集相比，真实数据集总是呈现出长尾的偏态分布[15,28]，即少数类(又称head类)占据了大部分数据，而大多数类(又称tail类)样本很少，cf 图1。此外，近年来计算机视觉界构建并发布了越来越多反映现实挑战的长尾数据集，如iNaturalist[6]、LVIS[10]和RPC[31]。在处理这类视觉数据时，由于深度模型对数据的渴求以及长尾数据分布的极端类不平衡问题，深度学习方法无法实现突出的识别精度。

​	在文献中，处理长尾问题的突出而有效的方法是类再平衡策略，它被提出来缓解训练数据的极端不平衡。一般来说，类重平衡方法大致分为两类，即重采样[26,1,14,1,11,2,7,21,4]和成本敏感重加权[13,30,5,23]。因此，类重平衡直接影响深度网络分类器权值的更新，即促进分类器的学习是有效的。这就是为什么重新平衡可以在长尾数据上获得满意的识别精度。

​	然而，虽然再平衡方法有很好的最终预测，我们认为这些方法仍然有负面影响，也就是在某种程度上，它们也会出乎意料地损害学习到的深层特征的代表能力(即表示学习)。具体地说，当数据不平衡非常严重时，重采样有过采样过度拟合尾部数据的风险，也有过采样对整个数据分布不拟合的风险。为了重新加权，它会通过直接改变甚至反转数据呈现频率而扭曲原始分布。

​	作为我们工作的一个初步，通过进行验证实验，我们证明了我们的上述论点。具体来说，为了弄清再平衡策略是如何工作的，我们将深度网络的训练过程分为两个阶段，分别进行表示学习和分类器学习。在表示学习的前一阶段，我们采用普通训练(传统的交叉熵)、重加权和重采样三种学习方式来获得相应的学习表示。在分类器学习的后一阶段，我们首先确定前一阶段收敛的表示学习(即骨干层)的参数，然后再用上述三种学习方式从头开始对这些网络(即全连接层)的分类器进行再训练。在图2中，报告了两个基准长尾数据集[3]的预测错误率，即CIFAR-100-IR50和CIFAR-10-IR50。显然，在确定表示学习方式时，重新平衡方法可以合理地降低错误率，说明它们可以促进分类器的学习。另一方面，通过固定分类器的学习方式，根据原始不平衡数据的较好特性，对其进行简单的训练可以获得较好的效果。此外，重新平衡方法的糟糕结果证明，它们将损害特征学习。



