# Rethinking the Value of Labels for Improving Class-Imbalanced Learning

我们分别从理论和实验上验证了，对于类别不均衡的学习问题，利用半监督学习 --- 也即利用更多的无标签数据；或者，自监督学习 --- 不利用任何其他数据，仅通过在现有的不平衡数据上先做一步不带标签信息的自监督预训练（self-supervised pre-training），都可以大大提升模型的表现，并且对于不同的平衡/不平衡的训练方法，从最基本的交叉熵损失，到进阶的类平衡损失，重采样，重加权，以及之前的state-of-the-art最优的decouple算法等，都能带来一致的&较大的提升。相信我们从和现有方法正交的角度的分析，可以作为解决不平衡长尾问题的新的思路，其简单和通用性也使得能够很容易和不同方法相结合，进一步提升学习结果。



## 研究背景

​		数据不平衡问题在现实世界中非常普遍。对于真实数据，不同类别的数据量一般不会是理想的uniform分布，而往往会是不平衡的；如果按照不同类别数据出现的频率从高到低排序，就会发现数据分布出现一个“长尾巴”，也即我们所称的长尾效应。大型数据集经常表现出这样的长尾标签分布：

![img](https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2020%2F1007%2F144bb1bfp00qhu4ve00agd200u000ikg00it00bm.png&thumbnail=650x2147483647&quality=80&type=jpg)

​		当然，不仅仅是对于分类任务，其他任务比如object detection或instance segmentation，常用数据集也存在类别的不均衡。

​		此外，除了视觉领域中的数据，对于涉及安全或健康的关键应用，例如自动驾驶和医疗/疾病诊断，数据本质上也是严重失衡的。

### 为什么会存在不平衡的现象？

​		其实很好理解，一个通用的解释就是特定类别的数据是很难收集的。

　　拿Species分类来说（参考大型数据集iNaturalist），特定种类（如猫，狗等）非常常见，但是有的种类（如高山兀鹫，随便举的例子...）就非常稀有。

　　再比如对自动驾驶，正常行驶的数据会占大多数，而真正发生异常情况/存在车祸危险的数据却极少。

　　再比如对医疗诊断，患有特定疾病的人群数相比正常人群也是极度不平衡的。对于healthcare data来说另一个可能原因是和privacy issue有关，特定病人可能都很难采集数据。

### 那么，不平衡或长尾数据会有什么问题？

　　简单来说，如果直接把类别不平衡的样本丢给模型用ERM学习，显然模型会在major classes的样本上的学习效果更好，而在minor classes上泛化效果差，因为其看到的major classes的样本远远多于minor classes。

　　那么，对于不平衡学习问题有哪些解决方法？我自己总结的目前主流方法大致分为以下几种：

　　重采样（re-sampling）： 更具体可分为对少样本的过采样，或是对多样本的欠采样[8]。但因过采样容易overfit到minor class，无法学到更鲁棒易泛化的特征，往往在非常不平衡数据上表现会更差；而欠采样则会造成major class严重的信息损失，导致欠拟合发生。

　　数据合成（synthetic samples）： 即生成和少样本相似的“新”数据。经典方法SMOTE[9]，思路简单来讲是对任意选取的少类样本，用K近邻选取其相似样本，通过对样本线性插值得到新样本。这里会想到和mixup[10]很相似，于是也有imbalance的mixup版本出现。

　　重加权（re-weighting）： 对不同类别（甚至不同样本）分配不同权重。注意这里的权重可以是自适应的。此类方法的变种有很多，有最简单的按照类别数目的倒数来做加权，按照“有效”样本数加权，根据样本数优化分类间距的loss加权，等等。

　　迁移学习（transfer learning）： 这类方法的基本思路是对多类样本和少类样本分别建模，将学到的多类样本的信息/表示/知识迁移给少类别使用。代表性文章有[13][14]。

　　度量学习（metric learning）： 本质上是希望能够学到更好的embedding，对少类附近的boundary/margin更好的建模。有兴趣的同学可以看看[15][16]。

　　元学习/域自适应（meta learning/domain adaptation）： 分别对头部和尾部的数据进行不同处理，可以去自适应的学习如何重加权，或是formulate成域自适应问题[18]。

　　解耦特征和分类器（decoupling representation & classifier）： 最近的研究发现将特征学习和分类器学习解耦，把不平衡学习分为两个阶段，在特征学习阶段正常采样，在分类器学习阶段平衡采样，可以带来更好的长尾学习结果。这也是目前的最优长尾分类算法。

　　至此大概总结了研究背景和常用方法；然而，即使有如数据重采样或类平衡损失等专门设计的算法，在极端的类别失衡下，深度模型性能的下降仍然广泛存在。

　　因此，理解类别不均衡的数据标签分布所带来的影响是非常重要的。

## 研究动机和思路

​		不同于之前对于长尾分布研究方法，我们从“the value of labels”，即这些本身就不平衡的数据标签具有的“价值”这一思路去考虑。

　　与理想情况下平衡的标签不同，这些不平衡的数据标签存在一个非常有趣的dilemma。一方面，这些标签提供了非常珍贵的监督信息。

　　有监督的学习通常都比无监督的学习在给定任务上具有更高准确性，因此即使不平衡，这些标签也拥有“正面价值”。

　　但是另一方面，由于标签非常不平衡，训练模型的过程中可以非常自然地强加上label bias，从而使得最后的决策区域很大程度上被major class影响；这样的结果又证明了不平衡标签的“负面价值”。

　　作为总结，在不平衡的训练集中，这些标签就像一把双刃剑；想要得到更好的结果，一个非常重要的问题就是如何最大程度的利用不平衡标签的“价值”？

　　于是，我们尝试系统性的分解并且分别分析上述两种不同的角度。我们的结论表明对于正面的和负面的角度，不平衡标签的价值都可被充分利用，从而极大的提高最后分类器的准确性：

　　从正面价值的角度 ，我们发现当有更多的无标签数据时，这些不平衡的标签提供了稀缺的监督信息。

　　通过利用这些信息，我们可以结合半监督学习去显著的提高最后的分类结果，即使无标签数据也存在长尾分布。

　　从负面价值的角度 ，我们证明了不平衡标签并非在所有情况下都是有用的。标签的不平衡大概率会产生label bias。

　　因此在训练中，我们首先想到“抛弃”标签的信息，通过自监督的学习方式先去学到好的起始表示形式。我们的结果表明通过这样的自监督预训练方式得到的模型也能够有效的提高分类的准确性。

​	    就是说，不平衡的标签有好的作用和坏的作用，好的是可以提供监督信息，坏的方面在于数据不平衡

## 半监督框架下的不均衡学习

​		我们首先从半监督的不均衡学习说起，通过一个简单的理论模型分析来建立直观的解释（省去了许多细节；可以直接跳到解释部分），之后展示一些有意思的实验结果。

　　理论分析：我们先从一个简单的toy example入手。考虑一个不同均值， 和 ，但是相同方差的Guassian mixture模型，我们可以很容易验证其贝叶斯最优分类器为： 。因此为了更好的分类，我们希望学习到他们的平均均值， 。假设我们已有一个在不平衡的训练集上得到的基础分类器 以及一定量的无标签的数据，我们可以通过这个基础分类器给这些数据做pseudo-label。令 和 代表pseudo-label为正和为负的数据的数量。为了估计 ，最简单的方法我们可以通过pseudo-label给这些对应的没有标签的数据取平均得到 。假设 代表基础分类器对于两个类的准确度的gap。这样的话我们推出以下定理：